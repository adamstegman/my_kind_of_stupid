{"data":{"markdownRemark":{"html":"<p>\n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 960px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 67.85%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABAAF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAdgB3oaZL//EABoQAAICAwAAAAAAAAAAAAAAAAECERIDEBP/2gAIAQEAAQUCgRkZbKRWWZ+Y1//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABkQAQACAwAAAAAAAAAAAAAAAAAhIgExYf/aAAgBAQAGPwLiJaWysh//xAAaEAACAwEBAAAAAAAAAAAAAAABEQAhMVFh/9oACAEBAAE/ISBcgBBfLyKgQryEE0pLkfdlMqgn/9oADAMBAAIAAwAAABA/L//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABYRAQEBAAAAAAAAAAAAAAAAAAAxEf/aAAgBAgEBPxCVr//EAB4QAAICAgIDAAAAAAAAAAAAAAERACExUUFxgbHh/9oACAEBAAE/EG+gDDS8wKLSyYbfP2ANUFfrLWGQE5U67gBAq0AKrUJKIAKCc//Z'); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Queue of people in a plaza\"\n        title=\"\"\n        src=\"/static/825e5873fbcf9842685a2c5b3540cd28/fa9d5/elastic-beanstalk-migrating-background-jobs-to-sqs.jpeg\"\n        srcset=\"/static/825e5873fbcf9842685a2c5b3540cd28/30a96/elastic-beanstalk-migrating-background-jobs-to-sqs.jpeg 240w,\n/static/825e5873fbcf9842685a2c5b3540cd28/288d4/elastic-beanstalk-migrating-background-jobs-to-sqs.jpeg 480w,\n/static/825e5873fbcf9842685a2c5b3540cd28/fa9d5/elastic-beanstalk-migrating-background-jobs-to-sqs.jpeg 960w,\n/static/825e5873fbcf9842685a2c5b3540cd28/78106/elastic-beanstalk-migrating-background-jobs-to-sqs.jpeg 1440w,\n/static/825e5873fbcf9842685a2c5b3540cd28/fb391/elastic-beanstalk-migrating-background-jobs-to-sqs.jpeg 1920w,\n/static/825e5873fbcf9842685a2c5b3540cd28/11ea9/elastic-beanstalk-migrating-background-jobs-to-sqs.jpeg 2000w\"\n        sizes=\"(max-width: 960px) 100vw, 960px\"\n      />\n    </span>\n  </span>\n  \nPhoto by <a href=\"https://unsplash.com/photos/VY1EDHABTDE\">Paul Dufour</a> on <a href=\"https://unsplash.com/\">Unsplash</a></p>\n<p>This article is part of a series on migrating to <a href=\"https://aws.amazon.com/elasticbeanstalk/\">Elastic Beanstalk</a> from a <a href=\"http://12factor.net/\">12-factor</a> application platform.\nIt also introduces <a href=\"https://github.com/onemedical/elastic_beans\">our <code>elastic_beans</code> CLI</a>, a replacement for the built-in AWS eb CLI.\nFor an explanation of why we chose Elastic Beanstalk, and why we chose to write a replacement CLI, see <a href=\"./migrating-to-elastic-beanstalk\">the first article in the series</a>.</p>\n<ol>\n<li><a href=\"./migrating-to-elastic-beanstalk\">Migrating to Elastic Beanstalk</a></li>\n<li><a href=\"./elastic-beanstalk-end-to-end-encryption-and-private-networking\">End-to-End Encryption and Private Networking</a></li>\n<li>Migrating Background Jobs to SQS</li>\n<li><a href=\"./elastic-beanstalk-one-off-and-periodic-tasks\">Periodic Tasks</a></li>\n</ol>\n<p>One of the features of Elastic Beanstalk is <a href=\"http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-tiers.html\">dedicated worker environments</a>.\nJobs are enqueued for background processing on <a href=\"https://aws.amazon.com/sqs/\">Amazon SQS</a> and the workers execute jobs by sending an HTTP POST to <code>http://localhost/</code>.\nThis is not what we're used to with background job processing in Rails, but luckily there is <a href=\"https://rubygems.org/gems/active_elastic_job\">an active<em>elastic</em>job gem</a> that handles all of this for us using the built-in ActiveJob framework.\nHowever, there was a lot of work to do before this worked for us.</p>\n<h2>Migration</h2>\n<p>When we decided to migrate to Elastic Beanstalk, we had used <a href=\"https://github.com/collectiveidea/delayed_job\">delayed_job</a> for a few years as our queuing system.\nIt worked well enough, but there were occasional issues with deadlock in MySQL and we'd been wanting to migrate to something better-suited to a job queue.\nMigrating to Elastic Beanstalk provided us the opportunity to migrate to the built-in dedicated worker environments.</p>\n<p>We could have kept running delayed_job ourselves, but we decided not to.\nOne of our goals was to rely on our chosen platform as much as possible.\nUsing built-in solutions performs better, requires less maintenance, and will be better-supported.</p>\n<h2>Challenges</h2>\n<p>We had implicitly learned the flaws of delayed_job and designed a system that could not be seamlessly migrated to a new queuing system.</p>\n<p>We encountered a number of issues before and during this migration.\nThe basic principles of background processing were not changed, but the devil is in the details.\nWe had to grapple with changes to our development and operations practices as well as supporting Elastic Beanstalk from our worker instances.\nThe challenges I'll cover here are:</p>\n<ul>\n<li>Refactoring to support active<em>elastic</em>job</li>\n<li>Handling multiple queues in SQS</li>\n<li>Tracking pending jobs</li>\n<li>Race conditions</li>\n<li>Retrying failed jobs</li>\n<li>Supporting the Elastic Beanstalk health check</li>\n</ul>\n<h3>Refactoring</h3>\n<p>Rails version 4.2 <a href=\"http://guides.rubyonrails.org/4_2_release_notes.html#active-job\">introduced a new framework called ActiveJob</a> to unify background job queuing systems.\nBefore ActiveJob, each queuing system had its own API, including delayed<em>job.\nAccordingly, all of our background jobs were written directly against the delayed</em>job API, even after we upgraded to Rails 4.2.\nWith the advent of Elastic Beanstalk, we knew a refactoring was in order.</p>\n<p>The ActiveJob API is pretty simple: inherit from <code>ActiveJob::Base</code> and define a method called <code>#perform</code>.\nMost of our jobs were what delayed_job calls \"<a href=\"https://github.com/collectiveidea/delayed_job/tree/v4.1.1#custom-jobs\">custom jobs</a>,\" which use the same method, so these jobs could be seamlessly refactored by inheriting from <code>ActiveJob::Base</code>.</p>\n<p>Our error-handling used <a href=\"https://github.com/collectiveidea/delayed_job/tree/v4.1.1#hooks\">the delayed_job error hook</a>, so we needed to update our jobs to use <a href=\"http://guides.rubyonrails.org/active_job_basics.html#exceptions\">ActiveJob error-handling</a> instead.</p>\n<p>Less conveniently, delayed<em>job has [two other ways of enqueuing jobs]delayed</em>job queuing jobs].\nThese are not generic and needed a little more work to extract them into custom jobs.</p>\n<p>Once our jobs were working, we had a bit of auditing to do.\nOur database is HIPAA-compliant because we are protected from unauthorized access and encrypt data in flight and at rest.\nSome of our jobs relied on that HIPAA-compliance and had protected health information (PHI) or personally identifiable information (PII) in the arguments to <code>#perform</code>, which are serialized in the job queue.\nThis was no longer acceptable in SQS, because it is not secure enough.\nWe had to move that data into the database and fetch it when executing the job.</p>\n<h3>Multiple queues</h3>\n<p>Our background jobs have a number of different performance profiles.\nSome jobs are relatively quick, but numerous; other jobs are not as numerous but take on the order of minutes rather than seconds.\nWe have split our jobs into five different job queues to prioritize jobs better and avoid starving any particular kind of job.</p>\n<p>In delayed_job, the queue is just a column in the database table.\nWhen the worker starts, it polls a subset of queues and executes jobs it finds.</p>\n<p>With Elastic Beanstalk and SQS, each queue is physically separate, and each worker polls a single queue.\nThis means we need five separate worker environments to poll those five queues.</p>\n<p>A consequence of SQS's fully-realized queues is that the queues are no longer scoped to a single application; they share a global namespace within our AWS account.\nOur jobs all had hard-coded the logical queue name since it had just been stored in the database.\nNow, we needed to use environment variables to name each queue so the name could be determined at deploy-time.</p>\n<h3>Tracking pending jobs</h3>\n<p>In some cases, the result of a background job is made available to providers or patients, and we want to track the job until it is done to indicate that work is incomplete.</p>\n<p>With delayed_job, we could write database queries to do this.\nThe queries were a little messy since things like IDs are encoded in the <code>handler</code> as YAML, but querying was at least possible.</p>\n<p>SQS provides little visibility into pending messages.\nIts queues have simple receive-or-send interfaces.\nAdditionally, once a job is picked up by a worker, it becomes invisible to any other consumers for the duration of the <code>VisibilityTimeout</code> (more on this later).</p>\n<p>We decided to implement a job-tracking system ourselves using the <a href=\"http://guides.rubyonrails.org/v4.2/active_job_basics.html#callbacks\">built-in hooks of ActiveJob</a>.\nWe create a pending event for a particular job in <code>before_enqueue</code>, then create more events in <code>before_perform</code> and <code>after_perform</code>.\nThis solution has the added benefit of not being tied to any particular ActiveJob backend and will continue to work even if we migrate away from SQS.</p>\n<h3>Race conditions</h3>\n<p>Using ActiveJob callbacks helps expose another issue that SQS is affected by differently than delayed<em>job: race conditions.\nWith delayed</em>job, all work is done in database transactions, which keeps the producer (the web server) and the consumer (the job executor) in sync.\nWith SQS the queue is no longer synchronized with the data and can introduce race conditions.</p>\n<p>The general pattern of code affected by race conditions was enqueuing a job from within a database transaction.\nThis usually involved one of two things:</p>\n<ul>\n<li>enqueuing a job from within an explicit <code>ActiveRecord::Base::transaction</code></li>\n<li>enqueuing a job from within an ActiveRecord callback (e.g. <code>after_create</code>), which are also within transactions</li>\n</ul>\n<p>The latter was fixed by switching to <code>after_commit on: :create</code>.\nThe former was fixed by moving the enqueue outside the transaction, which was sometimes trivial and sometimes not.</p>\n<h3>Retrying</h3>\n<p>When a background job fails, it is often retried some amount of time later in the hopes that the failure was transient.\nA common pattern is to retry using <a href=\"https://en.wikipedia.org/wiki/Exponential_backoff\">exponential backoff</a>, which is what delayed<em>job does by default.\nOur jobs would try up to 10 attempts, which using [delayed</em>job's exponential backoff]<a href=\"https://github.com/collectiveidea/delayed_job/tree/v4.1.1#custom-jobs\">custom jobs</a> resulted in a total time span of 4.27 hours between initial execution and the final attempt.</p>\n<p>Retrying jobs in SQS is controlled by <a href=\"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html\">the <code>VisibilityTimeout</code> configuration</a> and the maximum receive count configured in <a href=\"http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html\">the redrive policy</a>.\nWhen a job executor receives a message, the message automatically becomes invisible to other consumers for the duration of the <code>VisibilityTimeout</code>.\nAfter this time, if the message has not been deleted yet, the receive will be counted as failed and the message will become available to consumers again, until the maximum receive count is reached.\nAs a consequence, if a job takes longer than the <code>VisibilityTimeout</code>, it may be performed more than once, even if it is successful.\nThe value of <code>VisibilityTimeout</code> should therefore be high enough for any job to complete.</p>\n<p>We decided to use the maximum allowed <code>VisibilityTimeout</code> of 30 minutes for our jobs.\nOccasionally some of our jobs take this long to process.\nAdditionally, with the same number of attempts we were already using (10), this would leave at minimum 4.5 hours between initial execution and the final attempt.\nAll of this would result in a similar timing profile after migrating to SQS.</p>\n<p>The <code>VisibilityTimeout</code> can be configured in two ways:</p>\n<ul>\n<li>a static value configured in the queue</li>\n<li>a value from the consumer when using the ReceiveMessage API</li>\n</ul>\n<p>In the case of background job execution, <a href=\"http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-tiers.html#worker-daemon\">the AWS SQS daemon</a> uses the second option via <a href=\"http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/command-options-general.html#command-options-general-elasticbeanstalksqsd\">its own configuration</a>.</p>\n<p>Since the SQS daemon uses an HTTP POST request to execute jobs, there's one more, hidden, piece of configuration: nginx's <code>proxy_read_timeout</code>.\n<a href=\"http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_read_timeout\">By default, this is only 60 seconds</a>.\nAfter that time, nginx returns a 504 timeout error status to the daemon, and the job is considered failed.\nWe had to increase this to match our <code>VisibilityTimeout</code> by adding <a href=\"http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/customize-containers-ec2.html#linux-commands\">an ebextension with a command</a> to our application:</p>\n<div class=\"gatsby-highlight\">\n      <pre class=\"language-none\"><code>commands:\n  worker_configure_nginx:\n    command: |\n      echo 'proxy_read_timeout 1800s;' \\\n        >> /etc/nginx/conf.d/nginx.conf\n    test: test -f /opt/elasticbeanstalk/lib/ruby/bin/aws-sqsd</code></pre>\n      </div>\n<p>We also have <a href=\"https://github.com/heroku/rack-timeout\">rack-timeout</a> loaded in our application to terminate long-running requests, which needed a similar adjustment.</p>\n<h3>Health check</h3>\n<p>The AWS SQS daemon performs its own health check to <a href=\"http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/command-options-general.html#command-options-general-elasticbeanstalkapplication\">the Application Healthcheck URL</a> to ensure that the application can accept jobs to execute.\nUnfortunately, while the load balancer can support <a href=\"./elastic-beanstalk-end-to-end-encryption-and-private-networking\">end-to-end encryption</a> and perform a health check over HTTPS, the SQS daemon cannot.\nIn a worker environment, the Application Healthcheck URL must be HTTP.</p>\n<p>We <a href=\"https://github.com/onemedical/elastic_beans#health-check\">added a middleware to <code>elastic_beans</code></a> to handle these health checks if the request looks like it's from the SQS daemon: it's from localhost, and is a GET request to <code>/</code>.</p>\n<h2>Configuring with <code>elastic_beans</code></h2>\n<p>We created a Rails initializer to use the middleware provided by <code>elastic_beans</code>:</p>\n<div class=\"gatsby-highlight\">\n      <pre class=\"language-none\"><code>require \"elastic_beans/rack/health_check\"\n\nif Rails.configuration.force_ssl\n  Rails.configuration.middleware.insert_before(\n    ActionDispatch::SSL,\n    ElasticBeans::Rack::HealthCheck,\n    logger: Rails.logger,\n  )\nelse\n  Rails.configuration.middleware.use(\n    ElasticBeans::Rack::HealthCheck,\n    logger: Rails.logger,\n  )\nend</code></pre>\n      </div>\n<p>Creating worker environments using <code>elastic_beans</code> involved a couple steps.\nFirst we set up CloudFormation outputs that <code>elastic_beans</code> could discover when configuring the application.\nWe created our Elastic Beanstalk application using a CloudFormation template that also created other AWS resources needed by the application, including our five worker queues in SQS.\nWe added those queue URLs to the outputs of the <code>myapp</code> CloudFormation stack following the convention that <code>elastic_beans</code> understands: <code>Worker${Queue}QueueUrl</code>:</p>\n<div class=\"gatsby-highlight\">\n      <pre class=\"language-none\"><code>\"Outputs\": {\n  \"WorkerDefaultQueueUrl\": {\n    \"Value\": {\"Ref\": \"WorkerDefaultQueue\"}\n  },\n  \"WorkerMailersQueueUrl\": {\n    \"Value\": {\"Ref\": \"WorkerMailersQueue\"}\n  }\n}</code></pre>\n      </div>\n<p>Then, after <a href=\"./elastic-beanstalk-end-to-end-encryption-and-private-networking\">running <code>beans configure</code> to set up the application</a>, we could create worker environments for each queue:</p>\n<div class=\"gatsby-highlight\">\n      <pre class=\"language-none\"><code>beans create worker -q default -a myapp\nbeans create worker -q mailers -a myapp</code></pre>\n      </div>\n<h2>Reflections</h2>\n<p>We outlined a lot of challenges in migrating from delayed_job to SQS, but overall this went pretty smoothly.\nA little forethought and testing meant we hardly noticed the difference.\nThe biggest surprises were race conditions and the lack of HTTPS support from the SQS daemon health check.</p>\n<p>This was an exciting change for us to be able to make.\nWe had already outgrown delayed_job, and migrating our application to Elastic Beanstalk ended up being a perfect way to switch job queuing systems.</p>\n<h2>Elastic Beanstalk Migration</h2>\n<p>Overall the migration process has been fairly straightforward.\n<code>elastic_beans</code> has helped the Core Infrastructure group spare the rest of the team from most of these difficulties.\nWe are excited to be using a more secure, compliant, and scalable hosting platform!</p>\n<p>In future articles in this series, I will cover some of the issues we have overcome and how <code>elastic_beans</code> helps us solve them.</p>\n<ol>\n<li><a href=\"./migrating-to-elastic-beanstalk\">Migrating to Elastic Beanstalk</a></li>\n<li><a href=\"./elastic-beanstalk-end-to-end-encryption-and-private-networking\">End-to-End Encryption and Private Networking</a></li>\n<li>Migrating Background Jobs to SQS</li>\n<li><a href=\"./elastic-beanstalk-one-off-and-periodic-tasks\">Periodic Tasks</a></li>\n</ol>","fields":{"post":{"title":"Elastic Beanstalk: Migrating Background Jobs to SQS","link":null,"timestamp":"2017-02-09T18:20Z","date":"February 9, 2017 6:20pm UTC"}}}},"pageContext":{"slug":"/elastic-beanstalk-migrating-background-jobs-to-sqs"}}